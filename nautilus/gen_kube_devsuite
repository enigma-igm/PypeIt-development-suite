#!/usr/bin/env python3
#
# See top-level LICENSE.rst file for Copyright information
#
# -*- coding: utf-8 -*-

"""
This script generates a kubernetes YAML file to run the PypeIt development suite 
"""

import shutil
import os
import io, yaml

from pkg_resources import resource_filename

from IPython import embed

def parser(options=None):
    import argparse

    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter,
                                     description='Generate a kubernetes YAML file for a Nautilus dev suite job')

    parser.add_argument('name', type=str, default=None, help='Name of the job')
    parser.add_argument('outfile', type=str, default=None, help='Name of the YAML outfile')
    parser.add_argument('--pypeit_branch', type=str, default='develop', help='Name of the PypeIt branch to test')
    parser.add_argument('--dev_branch', type=str, default='develop', help='Name of the PypeIt Dev-Suite branch to use')
    parser.add_argument('--ncpu', type=int, default=6, help='Number of CPUs request')
    parser.add_argument('--ram', type=int, default=50, help='Amount of RAM to request (Gi)')
    #parser.add_argument('-d', '--dryrun', default=False, action='store_true',
    #                    help='Only list the steps')

    return parser.parse_args() if options is None else parser.parse_args(options)


def main():

    pargs = parser()

    # Load the default
    def_yaml_file = os.path.join(os.getenv('PYPEIT_DEV'), 'nautilus', 'kube_dev_suite.yaml')
    with open(def_yaml_file, 'r') as stream:
        data = yaml.safe_load(stream)

    # Modify
    data['metadata']['name'] = pargs.name

    # Resources
    requests = data['spec']['template']['spec']['containers'][0]['resources']['requests']
    requests['cpu'] = str(pargs.ncpu)
    requests['memory'] = f'{pargs.ram}Gi'

    # Limits
    limits = data['spec']['template']['spec']['containers'][0]['resources']['limits']
    limits['cpu'] = str(pargs.ncpu + 1)
    limits['memory'] = f'{2*pargs.ram}Gi'

    # Args
    my_args = 'cd PypeIt;'
    my_args += ' git fetch;'
    my_args += f' git checkout {pargs.pypeit_branch};' 
    my_args += ' git pull --ff-only;'
    # Telluric
    my_args += ' cd pypeit/data/telluric/atm_grids;'
    my_args += ' aws --endpoint http://rook-ceph-rgw-nautiluss3.rook s3 cp s3://pypeit/telluric/atm_grids/TelFit_MaunaKea_3100_26100_R20000.fits TelFit_MaunaKea_3100_26100_R20000.fits --force;'
    my_args += ' aws --endpoint http://rook-ceph-rgw-nautiluss3.rook s3 cp s3://pypeit/telluric/atm_grids/TelFit_LasCampanas_3100_26100_R20000.fits TelFit_LasCampanas_3100_26100_R20000.fits --force;'
    # Dev suite
    my_args += ' cd /;'
    my_args += ' cd PypeIt-development-suite;'
    my_args += ' git fetch;'
    my_args += f' git checkout {pargs.dev_branch};'
    my_args += ' git pull --ff-only;'
    # Pixel flat
    my_args += ' mkdir CALIBS;'
    my_args += ' aws --endpoint http://rook-ceph-rgw-nautiluss3.rook s3 cp s3://pypeit/CALIBS CALIBS/ --recursive --force;'
    # Raw Data
    my_args += ' mkdir RAW_DATA;'
    my_args += ' aws --endpoint http://rook-ceph-rgw-nautiluss3.rook s3 cp s3://pypeit/RAW_DATA RAW_DATA/ --recursive --force;'
    my_args += f' ./pypeit_test -q -t {pargs.ncpu} develop -r pypeit.report -o /tmp/REDUX_OUT;'
    my_args += f' aws --endpoint http://rook-ceph-rgw-nautiluss3.rook s3 cp pypeit.report s3://pypeit/Reports/{pargs.name}.report;'

    data['spec']['template']['spec']['containers'][0]['args'][0] = my_args

    with io.open(pargs.outfile, 'w', encoding='utf8') as outfile:
        yaml.dump(data, outfile, default_flow_style=False, allow_unicode=True)

if __name__ == '__main__':
    # Giddy up
    main()