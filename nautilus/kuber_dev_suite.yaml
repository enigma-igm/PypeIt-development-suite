# Script to perform PypeIt Dev Suite
#  Jumping into a pod -- kubectl exec -it pod-name -- /bin/bash
apiVersion: batch/v1
kind: Job
metadata:
  name: xavier-dev-suite-v0
spec:
  backoffLimit: 0
  template:
    spec:
      containers:
      - name: container
        image: localhost:30081/profxj/pypeit:latest  # UPDATE
        imagePullPolicy: Always
        resources:
          requests:
            cpu: "2"
            memory: "20Gi"
            ephemeral-storage: 150Gi
          limits:
            cpu: "10"
            memory: "300Gi"
            ephemeral-storage: 200Gi
            #nvidia.com/gpu:  "1"  # See docs to exlude certain types
            # https://ucsd-prp.gitlab.io/userdocs/running/gpu-pods/
        command: ["/bin/bash", "-c"]
        args:
          - sleep 900;
            cd PypeIt;  
            git checkout develop;
            cd /;
            cd PypeIt-development-suite;
            git checkout develop;
            mkdir RAW_DATA;
            aws --endpoint http://rook-ceph-rgw-nautiluss3.rook s3 cp s3://pypeit/RAW_DATA RAW_DATA/ --recursive --force;
            ./pypeit_test -t 2 develop;
        env:
          - name: "PYPEIT_DEV"
            value: "/PypeIt-development-suite"
          - name: "ENDPOINT_URL"
            value: "http://rook-ceph-rgw-nautiluss3.rook"
          - name: "S3_ENDPOINT"
            value: "rook-ceph-rgw-nautiluss3.rook"
        volumeMounts:
          - name: prp-s3-credentials
            mountPath: "/root/.aws/credentials"
            subPath: "credentials"
          - name: ephemeral
            mountPath: "/tmp"
          - name: "dshm"
            mountPath: "/dev/shm"
      nodeSelector:
        nautilus.io/disktype: nvme
        gpu-type: "1080Ti"  # titan-xp
      restartPolicy: Never
      volumes:
        # Secrets file for nautilus s3 credentials .aws/credentials and .s3cfg
        - name: prp-s3-credentials
          secret:
            secretName: prp-s3-credentials
        # Shared memory (necessary for Python's multiprocessing.shared_memory module to work)
        - name: dshm
          emptyDir:
            medium: Memory
        # Ephemeral storage
        - name: ephemeral
          emptyDir: {}